{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "landscapes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDeqDr1Gy3epE0/hcNF77+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ9KdeTX-TkG"
      },
      "source": [
        "# landscape classification\n",
        "\n",
        "In this case study, we will be exploring the use of convolution neural networks to classify images of landscapes. Identifying landsacpe or vegetation or land-use types from image data has important applications in agriculture and natural-resource management.\n",
        "\n",
        "In this example, we'll be using a data set of images from the following possible types or classes:\n",
        "\n",
        "* buildings representing cities or other human habitations\n",
        "* forests\n",
        "* glacier or ice-covered landscapes\n",
        "* mountains\n",
        "* sea or ocean\n",
        "* streets or paved areas\n",
        "\n",
        "I've packaged the image data into separate training and validation sub-sets, available for downoad at zenodo.\n",
        "\n",
        "The following code cell will download the image data sets, confirm the number of images in each sub-set, and package the data sets into tensorflow Dataset objects for neural network training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qud17b4f-SwC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "# download training data\n",
        "train_url = 'https://zenodo.org/record/5512793/files/train.tgz'\n",
        "train_dir = tf.keras.utils.get_file(origin=train_url, fname='train', untar=True)\n",
        "train_dir = pathlib.Path(train_dir)\n",
        "\n",
        "# download validation data\n",
        "valid_url = 'https://zenodo.org/record/5512793/files/valid.tgz'\n",
        "valid_dir = tf.keras.utils.get_file(origin=valid_url, fname='valid', untar=True)\n",
        "valid_dir = pathlib.Path(valid_dir)\n",
        "\n",
        "# print number of training and validation images\n",
        "train_image_count = len(list(train_dir.glob('*/*.jpg')))\n",
        "valid_image_count = len(list(valid_dir.glob('*/*.jpg')))\n",
        "print(train_image_count, valid_image_count)\n",
        "\n",
        "# package images into tensorflow dataset objects\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                 image_size=(150,150),\n",
        "                                                                 batch_size=32)\n",
        "valid_data = tf.keras.preprocessing.image_dataset_from_directory(valid_dir,\n",
        "                                                                 image_size=(150,150),\n",
        "                                                                 batch_size=32)\n",
        "# print tensorflow dataset objects\n",
        "print(train_data, valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKLNY0URJIw1"
      },
      "source": [
        "It should take a few seconds to download the data sets.\n",
        "\n",
        "You should see that there are 14,034 total image files in the training data sub-set, and 3000 images in the validation sub-set. In both cases, there are 6 possible classes or landscape types.\n",
        "\n",
        "Notice that the shape of the training and validation Dataset objects is the same:\n",
        "\n",
        "    ((None, 150, 150, 3), (None, ))\n",
        "\n",
        "That is, the image data (ignoring the batch dimension of None) consists of 150x150 pixel images with 3 color channels (ie, typical RGB image data). The labels are integer-valued class labels, which is pretty standard for image classification problems.\n",
        "\n",
        "We'll need to remember that the images are 150x150x3, so we can specify the correct input shape for our neural network.\n",
        "\n",
        "Also, we'll need to use SparseCategoricalCrossentropy loss when we fit our model to the training data, because the category labels are not one-hot encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NGBTTf-IT1-"
      },
      "source": [
        "To start off, we'll build a very simple convolution neural network consisting of a single convolution layer with a single 3x3 filter and ReLU activation.\n",
        "\n",
        "As a 'trick', we're going to automatically rescale our image data to be on the [0,1] scale *automatically* in our neural network. We'll do this by specifying a tf.keras.layers.experimental.preprocessing.Rescaling layer as the first layer in the network.\n",
        "\n",
        "Because our image data has pixel values between 0 and 255, we'll need to 'rescale' them by a factor of:\n",
        "\n",
        "    1.0/255\n",
        "\n",
        "which we specify as the scaling factor for the Rescaling layer. We'll also need to specify the input shape of the network when we create the Rescaling layer, because it's the first layer in the network.\n",
        "\n",
        "After 'flattening' the output of the convolution layer, we create a Dense output layer with 6 units (because there are 6 possible landscape classes), and softmax activation.\n",
        "\n",
        "We're going to opt for the Adam optimizer in this case, as it will help our model fit run faster (ie, fewer epochs). With this much data, we don't want to wait around for the slower SGD optimzer to reach a good model fit. The Adam optimizer is typically 'faster' than SGD, and it has been widely used for training image classification networks.\n",
        "\n",
        "Make sure we specify SparseCategoricalCrossentropy loss, record the model's accuracy as it trains, and we'll train for 20 epochs.\n",
        "\n",
        "Make sure you use GPU resources for this run, or it will take a *long* time! Click on the downward-facing arrow in the upper right corner of colab, select \"View resources\", and then click \"Change Runtime Type\". Select \"GPU\" from the \"Hardware acceleration\" drop-down, and save. Now your model fit will run on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX2xSelEJJcn"
      },
      "source": [
        "# build model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1.0/255, input_shape=[150,150,3]))\n",
        "model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation=tf.keras.activations.relu))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.activations.softmax))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "model.fit(train_data, epochs=20, validation_data=valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8QOnFgrMDnI"
      },
      "source": [
        "This model has 131,458 trainable parameters, nearly all of them in the Dense output layer.\n",
        "\n",
        "You'll notice that, with the Adam optimizer, the model reaches ~0.99 accuracy on the *training* data after only a few epochs of training. But, the accuracy on the *validation* data stays *very* low (around 0.38 in my case)!\n",
        "\n",
        "There is clearly an 'overfitting' problem. This makes sense, given that we have 14,034 training images and 131,458 model parameters!\n",
        "\n",
        "Let's try adding a Dropout layer to reduce overfitting.\n",
        "\n",
        "In the following code cell, we remove 90% of the outputs from the convolution layer, before flattening the data and sending it to the Dense output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETI5zaw4ywRO"
      },
      "source": [
        "# build model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1.0/255, input_shape=[150,150,3]))\n",
        "model.add(tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation=tf.keras.activations.relu))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.9))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.activations.softmax))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "model.fit(train_data, epochs=20, validation_data=valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVG7ycRR0fv4"
      },
      "source": [
        "Well, we appear to have alleviated model overfitting to the training data; the model's accuracy on the training and validation data sub-sets is much more similar.\n",
        "\n",
        "But, accuracy is pretty *low*, overall. In my case, I achieved a final model accuracy of 0.49 on the training data and 0.50 on the validation data. So, about 50% of the images are being correctly classified, but at least our model isn't overfitting.\n",
        "\n",
        "Let's see if we can improve model accuracy, without exacerbating overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoWSf40_K-Vp"
      },
      "source": [
        "XX - bigger network."
      ]
    }
  ]
}